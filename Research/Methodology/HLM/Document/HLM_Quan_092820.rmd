---
title: "HLM & What not..."
author: "Min Hwangbo"
date: "9/28/2020"
output:
  html_document:
    preserve_yaml: true
    toc: true
    toc_float: true
    keep_md: true
published: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Before we begin

## Context

* Below codes and references were documented throughout my PhD work at College of Education | Univ. of Washington
* If you are a UW student/staff, I highly recommend taking classes from Liz Sanders. These include the following: 
  * Hierarchical Linear Modeling (HLM | EDPSY576)
  * Structural Equation Modeling (SEM | EDPSY575)ßß
* I also recommend referencing the text from [Snijders, T. A. B., & Bosker, R. J. (2012). *Multilevel Analysis: An Introduction to Basic and Advanced Multilevel Modeling, second edition. London etc.: Sage Publishers.*](https://www.stats.ox.ac.uk/~snijders/mlbook.htm)
* Supplemental information & data from the textbook available [here](https://www.stats.ox.ac.uk/~snijders/mlbook.htm)
* As well as the ppt slides from [Snijers(2012)] (https://www.stats.ox.ac.uk/~snijders/MLB_new_S.pdf)
* If you're new to R, I have posted some slides on R including 1) Intro to RStudio & 2) Data transformation in R. Link to Workshop materials can be found [here](https://github.com/mhwangbo11/Workshop)

## Acknowledgement
>*“The University of Washington acknowledges that it sits on Indigenous Land, which touches the shared waters of all tribes and bands within the Duwamish, Suquamish, Tulalip, and Muckleshoot Tribes.”*
 
# Overview: HLM?
> "Hierarchical Linear Modeling (HLM) is a complex form of ordinary least squares (OLS) regression that is used to analyze variance in the outcome variables when the predictor variables are at varying hierarchical levels; for
example, students in a classroom share variance according to their common teacher and common classroom." ([Woltman et al., 2012, p.52](http://www.tqmp.org/RegularArticles/vol08-1/p052/p052.pdf))

And what do we mean by `variance`? Based on [Wikipedia](https://en.wikipedia.org/wiki/Variance):

* "Variance is the expectation of the squared deviation of a random variable from its mean."
* "Informally, it measures how far a set of numbers is spread out from their average value." 
* "Variance is an important tool in the sciences, where statistical analysis of data is common."
* "The variance is the square of the standard deviation, the second central moment of a distribution, and the covariance of the random variable with itself."

In sum, anyon who's interested in a statistical research modeling can apply HLM to explore shared variance in hierarchically structured data that has either 2-level or 3-level structure.

# Prepping
## Loading packages
Please install `lme4` package & `Matrix` package on your R Studio console before you load the package by using the code `install.packages("packagename")`
```{r, eval = F}
library(lme4)   # Linear Mixed-Effects Models Package
library(Matrix) # Package for hierarchy of matrix classes, etc
```

## ICC
Intraclass Correlation Coefficient (ICC) can be useful especially for a linear model that has a fixed variable as well as a random effect: the classic random intercept model. 

> You can calculate ICC once you have calculated the empty model (random effects ANOVA) which contains no explanatory variables which is "often between .05 and .25 in social science research" (Snijders, 2012, p.12).

* Intraclass correlation (*p*) = 
  * Level-two variance / (Level-two variance + Level-one variance) = 
  * Predicted variance / (Predicted variance + Residual variance)
* For instance if your ICC turns out to be .22, you can explain it as there is about 22 percent of variance in level 1 (micro-level) that is explained by level 2 (macro-level).

# 2-level model

## Step 1: Loading packages
```{r, message = F}
library(lme4)   # Linear Mixed-Effects Models Package
library(Matrix) # Package for hierarchy of matrix classes, etc
```

## Step 2: Loading data set
```{r, results = "hide"}
exampleDB <- read.csv("~/Documents/GitHub/InnovationLab/Research/Methodology/HLM/Data/mlbook2_r.dat", sep="") # This will need to be changed based on which directory you saved your data file. Data file available from Snijders's website referred in `context` section.

# Then perform a quality check
head(exampleDB, 5) # Clear
tail(exampleDB, 5) # Clear
ls(exampleDB) # 3758 vars, 11 vars (See RMD file to see the results)
```

## Step 3: Set up & Run an intercept-only (empty) model: M0

Let's assume language score (`langPOST`) as our outcome variable from micro-level (L1) and see whether the school mebmership (`schoolnr`) has any relationship.
```{r}
M0 <- lmer(langPOST ~ (1|schoolnr), data = exampleDB, REML = F)

# Then let's see how this one turns out...
summary(M0)
```
## Step 4: Interpretation of M0
Based on the M0 result, we know the following: 

* The overall distribution of the language scores (`langPOST`) of students provide a mean of 41.00 (FE intercept)
* The standard deviation of the langauge scores of students is $$\sqrt{18.13+62.75}$$= 8.99
* ICC for this model: 18.13/(18.13+62.85) = .22 meaning there is about 22 percent of variance in level 1 (`langPOST`) that is explained by school membership (`schoolnr`).
* It also indicates expected correlation between any 2 randomly selected L1 units (`langPOST`) for a given L2 (`schoolnr`) is *r* = 22.

> Is it worth it to perform a multi-level analysis? probably...

## Step 5a: Adding micro-level predictors: M1a
What if we add one explanatory variable (i.e. `IQ_verb`) and call it M1a?
```{r}
M1a <- lmer(langPOST ~ IQ_verb + (1|schoolnr), data = exampleDB, REML = F)
summary(M1a)
```
Based on the summary results:

* FE coefficient estimates in the model mean: 
  * Intercept: 41.05
  * IQ_verb: 2.51
* The model equation is y = 41.05 + U0j + 2.507IQ
* The model results indicate 41.05 mean IQ verbal score across all schools. 

* Class-dependent deviations of the intercept and have a mean of 0 and a variance of 9.85 that a standard deviation of $$\sqrt{9.85}$$= 3.14


## Step 5b: Adding micro-level predictors (standardized score): M1b
```{r}
M1b <-
```

## Step 6: Adding an interaction term: M2
```{r}
M2 <-
```

## Step 7a: Bayesian Information Criterion (BIC) test [(Raftery, 1995)](https://www.jstor.org/stable/271063)
```{r}
# BIC value: Lower = Better
bic(M1a, M1b, M2)
```

## Step 7b: Likelihood Ratio Test (LRT)
```{r}
lrtest(M1a, M1b, M2)
```



# 3-level model

# Growth model

# Misc.
